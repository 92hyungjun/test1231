root@S4:/workspace/FasterTransformer/build# export FT_DEBUG_LEVEL=DEBUG
root@S4:/workspace/FasterTransformer/build# export FT_LOG_LEVEL=DEBUG
root@S4:/workspace/FasterTransformer/build# 
root@S4:/workspace/FasterTransformer/build# 
root@S4:/workspace/FasterTransformer/build# python ../examples/pytorch/gpt/multi_gpu_gpt_example.py --data_type fp16 --max_batch_size=32 --input_len=32 --output_len=32 --shared_contexts_ratio=0 

=================== Arguments ===================
layer_num.....................: 24
input_len.....................: 32
output_len....................: 32
head_num......................: 16
size_per_head.................: 64
vocab_size....................: 50304
beam_width....................: 1
top_k.........................: 1
top_p.........................: 0.0
temperature...................: 1.0
len_penalty...................: 0.0
beam_search_diversity_rate....: 0.0
tensor_para_size..............: 1
pipeline_para_size............: 1
ckpt_path.....................: ../models/megatron-models/c-model/345m/1-gpu
lib_path......................: ./lib/libth_transformer.so
vocab_file....................: ../models/gpt2-vocab.json
merges_file...................: ../models/gpt2-merges.txt
start_id......................: 50256
end_id........................: 50256
max_batch_size................: 32
repetition_penalty............: 1.0
presence_penalty..............: 0.0
min_length....................: 0
max_seq_len...................: 1024
inference_data_type...........: fp16
time..........................: False
sample_input_file.............: None
sample_output_file............: None
enable_random_seed............: False
skip_end_tokens...............: False
detokenize....................: True
use_jieba_tokenizer...........: False
int8_mode.....................: 0
weights_data_type.............: fp32
return_cum_log_probs..........: 0
shared_contexts_ratio.........: 0.0
banned_words..................: 
use_gpt_decoder_ops...........: False
=================================================

[WARNING] gemm_config.in is not found; using default GEMM algo
[FT][INFO] Set logger level by DEBUG
[FT][DEBUG] void fastertransformer::ftNcclInitialize(fastertransformer::NcclParam&, fastertransformer::NcclParam&, int, int) start
[FT][WARNING] Skip NCCL initialization since requested tensor/pipeline parallel sizes are equals to 1.
[FT][INFO] Device NVIDIA A40
[FT][DEBUG] fastertransformer::cublasMMWrapper::cublasMMWrapper(cublasHandle_t, cublasLtHandle_t, cudaStream_t, fastertransformer::cublasAlgoMap*, std::mutex*, fastertransformer::IAllocator*)
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = void; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d4a000000 with size 33554432
[FT][DEBUG] void fastertransformer::ParallelGptContextDecoder<T>::initialize() [with T = __half]
[FT][DEBUG] fastertransformer::GptContextAttentionLayer<T>::GptContextAttentionLayer(size_t, size_t, size_t, size_t, size_t, cudaStream_t, fastertransformer::cublasMMWrapper*, fastertransformer::IAllocator*, bool, bool, bool, int) [with T = __half; size_t = long unsigned int; cudaStream_t = CUstream_st*]
[FT][DEBUG] fastertransformer::FfnLayer<T>::FfnLayer(size_t, size_t, size_t, size_t, size_t, size_t, cudaStream_t, fastertransformer::cublasMMWrapper*, fastertransformer::IAllocator*, bool, bool, int, bool) [with T = __half; size_t = long unsigned int; cudaStream_t = CUstream_st*]
[FT][DEBUG] fastertransformer::CubKeyValueSorter::CubKeyValueSorter()
[FT][DEBUG] fastertransformer::MoeGemmRunner<T, WeightType>::MoeGemmRunner() [with T = __half; WeightType = __half]
[FT][DEBUG] fastertransformer::CutlassMoeFCRunner<T, WeightType, Enable>::CutlassMoeFCRunner() [with T = __half; WeightType = __half; Enable = void]
[FT][DEBUG] fastertransformer::TensorParallelGeluFfnLayer<T>::TensorParallelGeluFfnLayer(size_t, size_t, size_t, size_t, size_t, size_t, fastertransformer::NcclParam, cudaStream_t, fastertransformer::cublasMMWrapper*, fastertransformer::IAllocator*, bool, bool, bool, int, bool, std::shared_ptr<fastertransformer::AbstractCustomComm>, int) [with T = __half; size_t = long unsigned int; cudaStream_t = CUstream_st*]
[FT][DEBUG] void fastertransformer::ParallelGptDecoder<T>::initialize() [with T = __half]
[FT][DEBUG] fastertransformer::FfnLayer<T>::FfnLayer(size_t, size_t, size_t, size_t, size_t, size_t, cudaStream_t, fastertransformer::cublasMMWrapper*, fastertransformer::IAllocator*, bool, bool, int, bool) [with T = __half; size_t = long unsigned int; cudaStream_t = CUstream_st*]
[FT][DEBUG] fastertransformer::CubKeyValueSorter::CubKeyValueSorter()
[FT][DEBUG] fastertransformer::MoeGemmRunner<T, WeightType>::MoeGemmRunner() [with T = __half; WeightType = __half]
[FT][DEBUG] fastertransformer::CutlassMoeFCRunner<T, WeightType, Enable>::CutlassMoeFCRunner() [with T = __half; WeightType = __half; Enable = void]
[FT][DEBUG] fastertransformer::TensorParallelGeluFfnLayer<T>::TensorParallelGeluFfnLayer(size_t, size_t, size_t, size_t, size_t, size_t, fastertransformer::NcclParam, cudaStream_t, fastertransformer::cublasMMWrapper*, fastertransformer::IAllocator*, bool, bool, bool, int, bool, std::shared_ptr<fastertransformer::AbstractCustomComm>, int) [with T = __half; size_t = long unsigned int; cudaStream_t = CUstream_st*]
[FT][DEBUG] fastertransformer::DynamicDecodeLayer<T>::DynamicDecodeLayer(size_t, size_t, int, cudaStream_t, fastertransformer::cublasMMWrapper*, fastertransformer::IAllocator*, bool, cudaDeviceProp*) [with T = float; size_t = long unsigned int; cudaStream_t = CUstream_st*]
[FT][DEBUG] void fastertransformer::DynamicDecodeLayer<T>::initialize() [with T = float]
[FT][DEBUG] void fastertransformer::DynamicDecodeLayer<T>::allocateBuffer() [with T = float]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1ccd000000 with size 32
[FT][DEBUG] void fastertransformer::ParallelGpt<T>::forward(std::unordered_map<std::__cxx11::basic_string<char>, fastertransformer::Tensor>*, const std::unordered_map<std::__cxx11::basic_string<char>, fastertransformer::Tensor>*, const fastertransformer::ParallelGptWeight<T>*) [with T = __half] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] void fastertransformer::ParallelGpt<T>::allocateBuffer(size_t, size_t, size_t, size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x7ffcf6ff0101, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226a0600 with size 65536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226b0600 with size 65536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226c0600 with size 65536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x7f207c96c1a4, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226d0600 with size 65536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226e0600 with size 65536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0xff01010000000000, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cd6800000 with size 6438912
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x4002, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cd4400000 with size 6438912
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x21f7720e17428d00, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f0600 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = bool; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x2, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f0800 with size 32
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f0a00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x4000000, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d3e000000 with size 201326592
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x7ffcf6af2e00, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f0c00 with size 8192
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x7ffcf6af2e30, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f2c00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = const __half*; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f2e00 with size 256
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x21f7720e17428d00, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f3000 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x1007ffcf6af2e00, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f3200 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0xff0101ff0101ff01, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f3400 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x55d5bbfd6780, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f3600 with size 8192
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0xe, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f5600 with size 8192
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f7600 with size 8192
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = unsigned int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f9600 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = bool; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226f9800 with size 2048
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x1, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cd9200000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x7f204968aec8, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cdb000000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer 0x7f2049692800, mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fa000 with size 8192
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = bool; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1ccd000200 with size 32
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fc000 with size 128
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:794
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: random_seed
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: min_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: len_penalty
[FT][DEBUG] void fastertransformer::DynamicDecodeLayer<T>::setup(size_t, size_t, fastertransformer::TensorMap*) [with T = float; size_t = long unsigned int]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: beam_search_diversity_rate
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key temperature
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: len_penalty
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key len_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: len_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: repetition_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: presence_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: min_length
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key min_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: min_length
[FT][DEBUG] void fastertransformer::TopKSamplingLayer<T>::setup(size_t, size_t, fastertransformer::TensorMap*) [with T = float; size_t = long unsigned int]
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::setup(size_t, size_t, fastertransformer::TensorMap*) [with T = float; size_t = long unsigned int]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] void fastertransformer::TopKSamplingLayer<T>::allocateBuffer(size_t, fastertransformer::Tensor, fastertransformer::Tensor) [with T = float; size_t = long unsigned int]
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::allocateBuffer(size_t, fastertransformer::Tensor, fastertransformer::Tensor) [with T = float; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = curandStateXORWOW; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fc200 with size 1536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = long long unsigned int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fc800 with size 256
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fca00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fcc00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fce00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cd4a24000 with size 6438912
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = bool; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fd000 with size 32
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = void; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cd5048000 with size 6440960
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = unsigned int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fd200 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fd400 with size 128
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: random_seed
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key random_seed
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: random_seed
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = long long unsigned int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/BaseSamplingLayer.cc:148
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key temperature
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: repetition_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: presence_penalty
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key min_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: min_length
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = float] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] void fastertransformer::TopPSamplingLayer<T>::setup(size_t, size_t, fastertransformer::TensorMap*) [with T = float; size_t = long unsigned int]
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::setup(size_t, size_t, fastertransformer::TensorMap*) [with T = float; size_t = long unsigned int]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] void fastertransformer::TopPSamplingLayer<T>::allocateBuffer(size_t, fastertransformer::Tensor, fastertransformer::Tensor) [with T = float; size_t = long unsigned int]
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::allocateBuffer(size_t, fastertransformer::Tensor, fastertransformer::Tensor) [with T = float; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = curandStateXORWOW; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fd600 with size 1536
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = long long unsigned int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fdc00 with size 256
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fde00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fe000 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fe200 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cc4800000 with size 6438912
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = bool; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fe400 with size 32
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = void; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d16000000 with size 25755904
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = unsigned int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fe600 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fe800 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fea00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fec00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226fee00 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226ff000 with size 128
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cc4e24000 with size 6438912
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226ff200 with size 160
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226ff400 with size 160
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: random_seed
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key random_seed
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: random_seed
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = long long unsigned int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/BaseSamplingLayer.cc:148
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key temperature
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: repetition_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: presence_penalty
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key min_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: min_length
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = float] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = float; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: top_p_decay
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: top_p_min
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: top_p_reset_ids
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/TopPSamplingLayer.cu:247
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: start_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: end_id
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:866
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:943
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:994
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:1020
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: last_token_hidden_units
[FT][DEBUG] void fastertransformer::ParallelGptContextDecoder<T>::forward(fastertransformer::TensorMap*, const fastertransformer::TensorMap*, const std::vector<fastertransformer::ParallelGptDecoderLayerWeight<T>*>*) [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: last_token_hidden_units
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: compact_idx
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] void fastertransformer::ParallelGptContextDecoder<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cdb200000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cdd000000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cdd200000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = long unsigned int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1ccd000400 with size 32
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d226ff600 with size 4096
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = int; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d22700600 with size 160
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer (nil) with size 0
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer (nil) with size 0
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer (nil) with size 0
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer (nil) with size 0
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/kernels/bert_preprocess_kernels.cu:68
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 0, original buffer: (nil), new buffer: 6291456
[FT][DEBUG] ReMalloc the buffer (nil) since it is too small.
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cc5448000 with size 6291456
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d17a00000 with size 6291456
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cc5c00000 with size 1048576
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cdf000000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1cdf200000 with size 2097152
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1ce1000000 with size 2097152
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] Cannot find buffer (nil), mallocing new one.
[FT][DEBUG] virtual void* fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::malloc(size_t, bool, bool)
[FT][DEBUG] malloc buffer 0x7f1d18000000 with size 8388608
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:488
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = __half; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key value_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: layer_id
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_batch
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: d_prefix_prompt_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cu_seqlens
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: linear_bias_slopes
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key hidden_features
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key attention_mask
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_mask
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: attention_type
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = fastertransformer::AttentionType] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = fastertransformer::AttentionType; size_t = long unsigned int] start
[FT][DEBUG] getVal with type x, but data type is: x
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::allocateBuffer(size_t, size_t, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1cc5448000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1cc5448000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 6291456, original buffer: 0x7f1d17a00000, new buffer: 6291456
[FT][DEBUG] Reuse original buffer 0x7f1d17a00000 with size 6291456 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 1048576, original buffer: 0x7f1cc5c00000, new buffer: 1048576
[FT][DEBUG] Reuse original buffer 0x7f1cc5c00000 with size 1048576 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1cdf200000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1cdf200000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = float; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 2097152, original buffer: 0x7f1ce1000000, new buffer: 2097152
[FT][DEBUG] Reuse original buffer 0x7f1ce1000000 with size 2097152 and do nothing for reMalloc.
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:74
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key is_final_layer
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_final_layer
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = bool] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = bool; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_query
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_query
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:143
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:173
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: value_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: key_cache
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:191
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:231
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:246
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:330
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/attention_layers/GptContextAttentionLayer.cc:401
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::AttentionWeight<T>*) [with T = __half] stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: hidden_features
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:634
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::TensorParallelGeluFfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] void fastertransformer::FfnLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*, const fastertransformer::FfnWeight<T>*) [with T = __half]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: moe_k
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::FfnLayer<T>::allocateBuffer(size_t, int, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] void* fastertransformer::IAllocator::reMalloc(T*, size_t, bool, bool) [with T = __half; size_t = long unsigned int]
[FT][DEBUG] current_buffer_size: 8388608, original buffer: 0x7f1d18000000, new buffer: 8388608
[FT][DEBUG] Reuse original buffer 0x7f1d18000000 with size 8388608 and do nothing for reMalloc.
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_scales
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expanded_source_row_to_expanded_dest_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: expert_for_source_row
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ffn_input
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ffn_input
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: padding_offset
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key ia3_tasks
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ia3_tasks
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:311
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int)
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, int, const void*, int, void*, int, float, float)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:302
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:373
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/FfnLayer.cc:379
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGptContextDecoder.cc:794
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key decoder_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key decoder_output
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: decoder_output
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key last_token_hidden_units
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: last_token_hidden_units
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = __half] start
[FT][DEBUG] void fastertransformer::ParallelGptContextDecoder<T>::forward(fastertransformer::TensorMap*, const fastertransformer::TensorMap*, const std::vector<fastertransformer::ParallelGptDecoderLayerWeight<T>*>*) [with T = __half] stop
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:1119
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:1352
[FT][DEBUG] void fastertransformer::cublasMMWrapper::Gemm(cublasOperation_t, cublasOperation_t, int, int, int, const void*, const void*, cudaDataType_t, int, const void*, cudaDataType_t, int, const void*, void*, cudaDataType_t, int, cudaDataType_t, cublasGemmAlgo_t)
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/utils/cublasMMWrapper.cc:134
[FT][DEBUG] void fastertransformer::DynamicDecodeLayer<T>::forward(std::unordered_map<std::__cxx11::basic_string<char>, fastertransformer::Tensor>*, const std::unordered_map<std::__cxx11::basic_string<char>, fastertransformer::Tensor>*) [with T = float]
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_k
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: runtime_top_p
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_seq_len
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: len_penalty
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: temperature
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_limit_length
[FT][DEBUG] src_cache_indirection is not a valid tensor, skipping insert into TensorMap
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: max_input_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: end_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ite
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: local_batch_size
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: min_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: is_initialize_random_table
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: random_seed
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: should_stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_length
[FT][DEBUG] output_log_probs is not a valid tensor, skipping insert into TensorMap
[FT][DEBUG] tgt_cache_indirection is not a valid tensor, skipping insert into TensorMap
[FT][DEBUG] cum_log_probs is not a valid tensor, skipping insert into TensorMap
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: parent_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: finished
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] void fastertransformer::DynamicDecodeLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*) [with T = float]
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ite
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ite
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = unsigned int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = unsigned int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key local_batch_size
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: local_batch_size
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: bad_words_list
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key end_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: end_id
[FT][DEBUG] void* fastertransformer::Tensor::getPtrWithOffset(size_t) const start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key max_input_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: max_input_length
[FT][DEBUG] void* fastertransformer::Tensor::getPtrWithOffset(size_t) const start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: max_input_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: end_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ite
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: embedding_bias
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key input_lengths
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: input_lengths
[FT][DEBUG] void* fastertransformer::Tensor::getPtrWithOffset(size_t) const start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_length
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key sequence_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_length
[FT][DEBUG] void* fastertransformer::Tensor::getPtrWithOffset(size_t) const start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: finished
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key finished
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: finished
[FT][DEBUG] void* fastertransformer::Tensor::getPtrWithOffset(size_t) const start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cum_log_probs
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_log_probs
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*) [with T = float] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ite
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ite
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key max_input_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: max_input_length
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: embedding_bias
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/BaseSamplingLayer.cc:313
[FT][DEBUG] void fastertransformer::TopKSamplingLayer<T>::runSampling(fastertransformer::TensorMap*, fastertransformer::TensorMap*) [with T = float]
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ite
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ite
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key finished
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: finished
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = bool] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key end_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: end_id
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/TopKSamplingLayer.cu:228
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: cum_log_probs
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_log_probs
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key end_id
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: end_id
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key finished
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: finished
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = bool] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&, fastertransformer::Tensor&&) for key sequence_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_length
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] T* fastertransformer::Tensor::getPtrWithOffset(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/TopKSamplingLayer.cu:267
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/layers/sampling_layers/BaseSamplingLayer.cc:357
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*) [with T = float] stop
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::forward(fastertransformer::TensorMap*, fastertransformer::TensorMap*) [with T = float] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key output_ids
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: output_ids
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key step
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: step
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key ite
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: ite
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key max_input_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: max_input_length
[FT][DEBUG] T fastertransformer::Tensor::getVal() const [with T = int] start
[FT][DEBUG] T fastertransformer::Tensor::getVal(size_t) const [with T = int; size_t = long unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key logits
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: logits
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = float] start
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: stop_words_list
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_limit_length
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key sequence_limit_length
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: sequence_limit_length
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = const unsigned int] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key should_stop
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: should_stop
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = bool] start
[FT][DEBUG] fastertransformer::Tensor& fastertransformer::TensorMap::at(const string&) for key finished
[FT][DEBUG] bool fastertransformer::TensorMap::isExist(const string&) const for key: finished
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = bool] start
[FT][DEBUG] void fastertransformer::invokeLengthCriterion(bool*, bool*, int*, const uint32_t*, int, int, int, cudaStream_t) start
[FT][DEBUG] run syncAndCheck at /workspace/FasterTransformer/src/fastertransformer/kernels/stop_criteria_kernels.cu:154
[FT][DEBUG] T* fastertransformer::Tensor::getPtr() const [with T = int] start
[FT][ERROR] [FT][ERROR] CUDA runtime error: an illegal memory access was encountered /workspace/FasterTransformer/src/fastertransformer/models/multi_gpu_gpt/ParallelGpt.cc:1264 

[FT][DEBUG] fastertransformer::FfnLayer<T>::~FfnLayer() [with T = __half]
[FT][DEBUG] void fastertransformer::FfnLayer<T>::freeBuffer() [with T = __half]
[FT][DEBUG] void fastertransformer::GptContextAttentionLayer<T>::freeBuffer() [with T = __half]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] fastertransformer::FfnLayer<T>::~FfnLayer() [with T = __half]
[FT][DEBUG] void fastertransformer::FfnLayer<T>::freeBuffer() [with T = __half]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] void fastertransformer::ParallelGptContextDecoder<T>::freeBuffer() [with T = __half]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] fastertransformer::DynamicDecodeLayer<T>::~DynamicDecodeLayer() [with T = float]
[FT][DEBUG] fastertransformer::OnlineBeamSearchLayer<T>::~OnlineBeamSearchLayer() [with T = float]
[FT][DEBUG] fastertransformer::BaseBeamSearchLayer<T>::~BaseBeamSearchLayer() [with T = float]
[FT][DEBUG] fastertransformer::BeamSearchLayer<T>::~BeamSearchLayer() [with T = float]
[FT][DEBUG] fastertransformer::BaseBeamSearchLayer<T>::~BaseBeamSearchLayer() [with T = float]
[FT][DEBUG] fastertransformer::TopKSamplingLayer<T>::~TopKSamplingLayer() [with T = float]
[FT][DEBUG] void fastertransformer::TopKSamplingLayer<T>::freeBuffer() [with T = float]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::freeBuffer() [with T = float]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] void fastertransformer::TopPSamplingLayer<T>::freeBuffer() [with T = float]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] void fastertransformer::BaseSamplingLayer<T>::freeBuffer() [with T = float]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] void fastertransformer::DynamicDecodeLayer<T>::freeBuffer() [with T = float]
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] fastertransformer::cublasMMWrapper::~cublasMMWrapper()
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
[FT][DEBUG] virtual fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::~Allocator()
[FT][DEBUG] virtual void fastertransformer::Allocator<fastertransformer::AllocatorType::TH>::free(void**, bool) const
Traceback (most recent call last):
  File "../examples/pytorch/gpt/multi_gpu_gpt_example.py", line 364, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "../examples/pytorch/gpt/multi_gpu_gpt_example.py", line 321, in main
    gen_outputs = gpt_generate_fn()
  File "../examples/pytorch/gpt/multi_gpu_gpt_example.py", line 302, in gpt_generate_fn
    tokens_batch = gpt(start_ids,
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1185, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/FasterTransformer/examples/pytorch/gpt/../../../examples/pytorch/gpt/utils/gpt.py", line 608, in forward
    outputs = self.model.forward(start_ids,
RuntimeError: [FT][ERROR]  Assertion fail: /workspace/FasterTransformer/src/fastertransformer/th_op/multi_gpu_gpt/ParallelGptOp.h:450 
